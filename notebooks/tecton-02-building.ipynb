{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìö Building a Production AI Application with Tecton\n",
    "---\n",
    "\n",
    "Tecton helps you build and productionize real-time ML models by making it easy\n",
    "to define, test, and deploy features for training and serving.\n",
    "\n",
    "Let‚Äôs see how quickly we can build a real-time fraud detection model and bring\n",
    "it online.\n",
    "\n",
    "In this tutorial we will:\n",
    "\n",
    "1. Connect to data on S3\n",
    "2. Define and test features\n",
    "3. Generate a training dataset and train a model\n",
    "4. Productionize our features for real-time serving\n",
    "5. Run real-time inference to predict fraudulent transactions\n",
    "\n",
    "This tutorial is expected to take about 30 minutes (record time for building a\n",
    "real-time ML application üòé).\n",
    "\n",
    "---\n",
    "\n",
    "##### üí° **TIP**\n",
    "\n",
    "Most of this tutorial is intended to be run in a notebook. Some steps will explicitly note to run commands in your terminal.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Install Pre-Reqs\n",
    "\n",
    "First things first, let's install the Tecton SDK and other libraries used in this tutorial by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install 'tecton[rift]' gcsfs s3fs scikit-learn --quiet --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Log in to Tecton\n",
    "\n",
    "Next we will authenticate with your organization's Tecton account.\n",
    "\n",
    "*Note: You need to press `enter` after pasting in your authentication code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already logged in to https://demo-pangolin.tecton.ai as UserProfile(name='Jonathan Varley', email='jon@tecton.ai', id='00ut35dahebreB27E357'). To switch users, run `tecton.logout` then `tecton.login`\n"
     ]
    }
   ],
   "source": [
    "import tecton\n",
    "\n",
    "tecton.login(\"demo-pangolin.tecton.ai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then run some basic imports and setup that we will use later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 0.9.12\n",
      "Git Commit: 7b1322f6df430b497a8fd0535186da3bf3ee6612\n",
      "Build Datetime: 2024-06-25T14:37:08\n"
     ]
    }
   ],
   "source": [
    "from tecton import Entity, BatchSource, FileConfig, batch_feature_view, Aggregation\n",
    "from tecton.types import Field, String, Timestamp, Float64\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "tecton.set_validation_mode(\"auto\")\n",
    "tecton.conf.set(\"TECTON_OFFLINE_RETRIEVAL_COMPUTE_MODE\", \"rift\")\n",
    "\n",
    "tecton.version.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build!\n",
    "\n",
    "## üîé Examine raw data\n",
    "\n",
    "First let's examine some historical transaction data that we have available on\n",
    "S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>merchant</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:27:59.442071</td>\n",
       "      <td>user_1990251765</td>\n",
       "      <td>e8bd834c108c0929cd757f79e65acca0</td>\n",
       "      <td>Whole Foods</td>\n",
       "      <td>-45.676907</td>\n",
       "      <td>-171.601424</td>\n",
       "      <td>28.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:11:01.384867</td>\n",
       "      <td>user_1284832379</td>\n",
       "      <td>0be03a2b9370b66073f0ed655423fa00</td>\n",
       "      <td>A&amp;F</td>\n",
       "      <td>-73.685249</td>\n",
       "      <td>66.545372</td>\n",
       "      <td>20.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 01:20:59.084788</td>\n",
       "      <td>user_9979340926</td>\n",
       "      <td>986eddaed2f4971b7d4d955dce678e28</td>\n",
       "      <td>Shaw's</td>\n",
       "      <td>84.224302</td>\n",
       "      <td>151.194256</td>\n",
       "      <td>98.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 01:22:08.889972</td>\n",
       "      <td>user_8096819426</td>\n",
       "      <td>f75d2872395660da185b4c82912ffb4a</td>\n",
       "      <td>Zales</td>\n",
       "      <td>88.399805</td>\n",
       "      <td>-171.109611</td>\n",
       "      <td>97.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 01:49:01.356931</td>\n",
       "      <td>user_8096819426</td>\n",
       "      <td>6112629434a2675e299b083cf96bfa7d</td>\n",
       "      <td>Quality Stores</td>\n",
       "      <td>-56.688061</td>\n",
       "      <td>-68.362769</td>\n",
       "      <td>27.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp          user_id  \\\n",
       "0 2020-01-01 00:27:59.442071  user_1990251765   \n",
       "1 2020-01-01 01:11:01.384867  user_1284832379   \n",
       "2 2020-01-01 01:20:59.084788  user_9979340926   \n",
       "3 2020-01-01 01:22:08.889972  user_8096819426   \n",
       "4 2020-01-01 01:49:01.356931  user_8096819426   \n",
       "\n",
       "                     transaction_id        merchant  merch_lat  merch_long  \\\n",
       "0  e8bd834c108c0929cd757f79e65acca0     Whole Foods -45.676907 -171.601424   \n",
       "1  0be03a2b9370b66073f0ed655423fa00             A&F -73.685249   66.545372   \n",
       "2  986eddaed2f4971b7d4d955dce678e28          Shaw's  84.224302  151.194256   \n",
       "3  f75d2872395660da185b4c82912ffb4a           Zales  88.399805 -171.109611   \n",
       "4  6112629434a2675e299b083cf96bfa7d  Quality Stores -56.688061  -68.362769   \n",
       "\n",
       "   amount  \n",
       "0   28.86  \n",
       "1   20.46  \n",
       "2   98.39  \n",
       "3   97.74  \n",
       "4   27.53  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "transactions_df = pd.read_parquet(\"s3://mft-porter-data/tutorials/transactions.pq\", storage_options={\"anon\": True})\n",
    "\n",
    "display(transactions_df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë©‚Äçüíª Define and test features locally\n",
    "\n",
    "In our data, we see that there's information on users' transactions over time.\n",
    "\n",
    "Let's use this data to create the following features:\n",
    "\n",
    "- A user's average transaction amount over 1, 3, and 7 days.\n",
    "- A user's total transaction count over 1, 3, and 7 days.\n",
    "\n",
    "To build these features, we will define a \"Batch Source\" and \"Batch Feature\n",
    "View\" using Tecton's Feature Engineering Framework.\n",
    "\n",
    "A Feature View is how we define our feature logic and give Tecton the\n",
    "information it needs to productionize, monitor, and manage features.\n",
    "\n",
    "Tecton's [development workflow](https://docs.tecton.ai/docs/the-feature-development-workflow) allows you\n",
    "to build and test features, as well as generate training data entirely in a\n",
    "notebook! Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = BatchSource(\n",
    "    name=\"transactions\",\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://mft-porter-data/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# An entity defines the concept we are modeling features for\n",
    "# The join keys will be used to aggregate, join, and retrieve features\n",
    "user = Entity(name=\"user\", join_keys=[\"user_id\"])\n",
    "\n",
    "# We use Pandas to transform the raw data and Tecton aggregations to efficiently and accurately compute metrics across raw events\n",
    "# Feature View decorators contain a wide range of parameters for materializing, cataloging, and monitoring features\n",
    "@batch_feature_view(\n",
    "    description=\"User transaction metrics over 1, 3 and 7 days\",\n",
    "    sources=[transactions],\n",
    "    entities=[user],\n",
    "    mode=\"pandas\",\n",
    "    aggregation_interval=timedelta(days=1),\n",
    "    aggregations=[\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=1)),\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=3)),\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=7)),\n",
    "        Aggregation(function=\"count\", column=\"amount\", time_window=timedelta(days=1)),\n",
    "        Aggregation(function=\"count\", column=\"amount\", time_window=timedelta(days=3)),\n",
    "        Aggregation(function=\"count\", column=\"amount\", time_window=timedelta(days=7)),\n",
    "    ],\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    ")\n",
    "def user_transaction_metrics(transactions):\n",
    "    return transactions[[\"user_id\", \"timestamp\", \"amount\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test features interactively\n",
    "\n",
    "Now that we've defined our Feature View, we can use\n",
    "`get_features_in_range` to produce a range of feature values and check out the\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchFeatureView 'user_transaction_metrics': Validating 3 dependencies.\n",
      "    BatchSource 'transactions': Successfully validated.\n",
      "    Entity 'user': Successfully validated.\n",
      "    Transformation 'user_transaction_metrics': Successfully validated.\n",
      "BatchFeatureView 'user_transaction_metrics': Successfully validated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount_mean_1d_1d</th>\n",
       "      <th>amount_mean_3d_1d</th>\n",
       "      <th>amount_mean_7d_1d</th>\n",
       "      <th>amount_count_1d_1d</th>\n",
       "      <th>amount_count_3d_1d</th>\n",
       "      <th>amount_count_7d_1d</th>\n",
       "      <th>_valid_to</th>\n",
       "      <th>_valid_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_4856370219</td>\n",
       "      <td>36.23</td>\n",
       "      <td>44.676667</td>\n",
       "      <td>29.130000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>2022-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_5638922576</td>\n",
       "      <td>43.51</td>\n",
       "      <td>49.003333</td>\n",
       "      <td>33.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>2022-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_6307583010</td>\n",
       "      <td>21.68</td>\n",
       "      <td>21.680000</td>\n",
       "      <td>28.606667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-02-01</td>\n",
       "      <td>2022-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_8041734544</td>\n",
       "      <td>30.65</td>\n",
       "      <td>446.495000</td>\n",
       "      <td>161.516250</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>2022-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_8175816267</td>\n",
       "      <td>45.13</td>\n",
       "      <td>45.130000</td>\n",
       "      <td>61.858000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>2022-01-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  amount_mean_1d_1d  amount_mean_3d_1d  amount_mean_7d_1d  \\\n",
       "0  user_4856370219              36.23          44.676667          29.130000   \n",
       "1  user_5638922576              43.51          49.003333          33.100000   \n",
       "2  user_6307583010              21.68          21.680000          28.606667   \n",
       "3  user_8041734544              30.65         446.495000         161.516250   \n",
       "4  user_8175816267              45.13          45.130000          61.858000   \n",
       "\n",
       "   amount_count_1d_1d  amount_count_3d_1d  amount_count_7d_1d  _valid_to  \\\n",
       "0                   1                   3                   6 2022-01-14   \n",
       "1                   1                   3                   5 2022-01-07   \n",
       "2                   1                   1                   3 2022-02-01   \n",
       "3                   1                   2                   8 2022-01-15   \n",
       "4                   1                   1                   5 2022-01-24   \n",
       "\n",
       "  _valid_from  \n",
       "0  2022-01-13  \n",
       "1  2022-01-06  \n",
       "2  2022-01-31  \n",
       "3  2022-01-14  \n",
       "4  2022-01-23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = datetime(2022, 1, 1)\n",
    "end = datetime(2022, 2, 1)\n",
    "\n",
    "df = user_transaction_metrics.get_features_in_range(start_time=start, end_time=end).to_pandas()\n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Generate training data\n",
    "\n",
    "We'll build our training dataset from labeled historical transactions and try to\n",
    "predict the \"is_fraud\" column for a given transaction.\n",
    "\n",
    "First, let's load our label dataset, which indicates whether a transaction in our historical dataset was fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e8bd834c108c0929cd757f79e65acca0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0be03a2b9370b66073f0ed655423fa00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>986eddaed2f4971b7d4d955dce678e28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f75d2872395660da185b4c82912ffb4a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6112629434a2675e299b083cf96bfa7d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     transaction_id  is_fraud\n",
       "0  e8bd834c108c0929cd757f79e65acca0         0\n",
       "1  0be03a2b9370b66073f0ed655423fa00         0\n",
       "2  986eddaed2f4971b7d4d955dce678e28         0\n",
       "3  f75d2872395660da185b4c82912ffb4a         0\n",
       "4  6112629434a2675e299b083cf96bfa7d         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_labels = pd.read_parquet(\"s3://mft-porter-data/tutorials/labels.pq\", storage_options={\"anon\": True})\n",
    "display(training_labels.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's join our transactions dataset to our label dataset (on the `transaction_id` column) to produce a set of training events we'll then use to generate our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1990251765</td>\n",
       "      <td>2020-01-01 00:27:59.442071</td>\n",
       "      <td>28.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1284832379</td>\n",
       "      <td>2020-01-01 01:11:01.384867</td>\n",
       "      <td>20.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_9979340926</td>\n",
       "      <td>2020-01-01 01:20:59.084788</td>\n",
       "      <td>98.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_8096819426</td>\n",
       "      <td>2020-01-01 01:22:08.889972</td>\n",
       "      <td>97.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_8096819426</td>\n",
       "      <td>2020-01-01 01:49:01.356931</td>\n",
       "      <td>27.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id                  timestamp  amount  is_fraud\n",
       "0  user_1990251765 2020-01-01 00:27:59.442071   28.86         0\n",
       "1  user_1284832379 2020-01-01 01:11:01.384867   20.46         0\n",
       "2  user_9979340926 2020-01-01 01:20:59.084788   98.39         0\n",
       "3  user_8096819426 2020-01-01 01:22:08.889972   97.74         0\n",
       "4  user_8096819426 2020-01-01 01:49:01.356931   27.53         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_events = training_labels.merge(transactions_df, on=[\"transaction_id\"], how=\"left\")[\n",
    "    [\"user_id\", \"timestamp\", \"amount\", \"is_fraud\"]\n",
    "]\n",
    "display(training_events.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's ask Tecton to join the features we just created into our labeled\n",
    "events. Tecton will perform a\n",
    "[time travel join](https://docs.tecton.ai/docs/reading-feature-data/reading-feature-data-for-training/constructing-training-data#a-note-on-point-in-time-correctness)\n",
    "to fetch point-in-time correct feature values.\n",
    "\n",
    "To do this we will create a \"Feature Service\" which defines the list of features\n",
    "that will be used by our model.\n",
    "\n",
    "We can call `get_features_for_events(training_events)` on the Feature Service to\n",
    "get historically accurate features for each event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureService 'fraud_detection_feature_service': Successfully validated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>user_transaction_metrics__amount_count_1d_1d</th>\n",
       "      <th>user_transaction_metrics__amount_count_7d_1d</th>\n",
       "      <th>user_transaction_metrics__amount_mean_3d_1d</th>\n",
       "      <th>user_transaction_metrics__amount_mean_7d_1d</th>\n",
       "      <th>user_transaction_metrics__amount_mean_1d_1d</th>\n",
       "      <th>user_transaction_metrics__amount_count_3d_1d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66084</th>\n",
       "      <td>user_9757807451</td>\n",
       "      <td>2023-08-29 17:15:36.796024</td>\n",
       "      <td>97.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16697</th>\n",
       "      <td>user_6853424150</td>\n",
       "      <td>2023-08-18 13:58:46.142559</td>\n",
       "      <td>741.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.560000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46693</th>\n",
       "      <td>user_5638922576</td>\n",
       "      <td>2022-03-16 04:51:57.981899</td>\n",
       "      <td>61.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>396.950000</td>\n",
       "      <td>168.230000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96976</th>\n",
       "      <td>user_2210887384</td>\n",
       "      <td>2023-11-09 17:22:29.134779</td>\n",
       "      <td>58.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>33.343333</td>\n",
       "      <td>70.840000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96741</th>\n",
       "      <td>user_1939957235</td>\n",
       "      <td>2024-12-31 23:39:23.640727</td>\n",
       "      <td>1000.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>261.417500</td>\n",
       "      <td>325.786667</td>\n",
       "      <td>194.74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id                  timestamp   amount  is_fraud  \\\n",
       "66084  user_9757807451 2023-08-29 17:15:36.796024    97.52         0   \n",
       "16697  user_6853424150 2023-08-18 13:58:46.142559   741.67         0   \n",
       "46693  user_5638922576 2022-03-16 04:51:57.981899    61.66         0   \n",
       "96976  user_2210887384 2023-11-09 17:22:29.134779    58.70         0   \n",
       "96741  user_1939957235 2024-12-31 23:39:23.640727  1000.02         1   \n",
       "\n",
       "       user_transaction_metrics__amount_count_1d_1d  \\\n",
       "66084                                             0   \n",
       "16697                                             0   \n",
       "46693                                             0   \n",
       "96976                                             0   \n",
       "96741                                             1   \n",
       "\n",
       "       user_transaction_metrics__amount_count_7d_1d  \\\n",
       "66084                                             1   \n",
       "16697                                             1   \n",
       "46693                                             9   \n",
       "96976                                             8   \n",
       "96741                                             6   \n",
       "\n",
       "       user_transaction_metrics__amount_mean_3d_1d  \\\n",
       "66084                                     0.770000   \n",
       "16697                                     0.000000   \n",
       "46693                                   396.950000   \n",
       "96976                                    33.343333   \n",
       "96741                                   261.417500   \n",
       "\n",
       "       user_transaction_metrics__amount_mean_7d_1d  \\\n",
       "66084                                     0.770000   \n",
       "16697                                    20.560000   \n",
       "46693                                   168.230000   \n",
       "96976                                    70.840000   \n",
       "96741                                   325.786667   \n",
       "\n",
       "       user_transaction_metrics__amount_mean_1d_1d  \\\n",
       "66084                                         0.00   \n",
       "16697                                         0.00   \n",
       "46693                                         0.00   \n",
       "96976                                         0.00   \n",
       "96741                                       194.74   \n",
       "\n",
       "       user_transaction_metrics__amount_count_3d_1d  \n",
       "66084                                             1  \n",
       "16697                                             0  \n",
       "46693                                             2  \n",
       "96976                                             3  \n",
       "96741                                             4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tecton import FeatureService\n",
    "\n",
    "fraud_detection_feature_service = FeatureService(\n",
    "    name=\"fraud_detection_feature_service\", features=[user_transaction_metrics]\n",
    ")\n",
    "\n",
    "training_data = fraud_detection_feature_service.get_features_for_events(training_events).to_pandas().fillna(0)\n",
    "display(training_data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Train a model\n",
    "\n",
    "Once we have our training data set from Tecton, we can use whatever framework we\n",
    "want for training the model.\n",
    "\n",
    "In the example below, we'll train a simple Logistic Regression model using\n",
    "sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95     26913\n",
      "           1       0.98      0.01      0.03      3087\n",
      "\n",
      "    accuracy                           0.90     30000\n",
      "   macro avg       0.94      0.51      0.49     30000\n",
      "weighted avg       0.91      0.90      0.85     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "df = training_data.drop([\"user_id\", \"timestamp\", \"amount\"], axis=1)\n",
    "\n",
    "X = df.drop(\"is_fraud\", axis=1)\n",
    "y = df[\"is_fraud\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "num_cols = X_train.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "num_pipe = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"N/A\"), OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    ")\n",
    "\n",
    "full_pipe = ColumnTransformer([(\"num\", num_pipe, num_cols), (\"cat\", cat_pipe, cat_cols)])\n",
    "\n",
    "model = make_pipeline(full_pipe, LogisticRegression(max_iter=1000, random_state=42))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_predict, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, you can continue building iterating on features and retraining your\n",
    "model until you are ready to productionize.\n",
    "\n",
    "## üöÄ Apply your Tecton application to production\n",
    "\n",
    "Tecton objects get registered via a declarative workflow. Features are defined\n",
    "as code in a repo and applied to a [workspace](https://docs.tecton.ai/docs/introduction/tecton-concepts#workspace) in a Tecton account using the\n",
    "Tecton CLI. A workspace is like a project for your team or org and corresponds to a single feature repository.\n",
    "\n",
    "This declarative workflow enables productionisation best practices such as\n",
    "\"features as code,\" CI/CD, and unit testing.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Create a Tecton Feature Repository\n",
    "\n",
    "Let's switch over from our notebook to a terminal and create a new Tecton\n",
    "Feature Repository. For now we will put all our definitions in a single file.\n",
    "\n",
    "‚úÖ Run these commands to create a new Tecton repo.\n",
    "\n",
    "```bash\n",
    "mkdir tecton-feature-repo\n",
    "cd tecton-feature-repo\n",
    "touch features.py\n",
    "tecton init\n",
    "```\n",
    "\n",
    "### 2. Fill in features.py and enable materialization\n",
    "\n",
    "‚úÖ Now copy & paste the definition of the Tecton objects you created in your\n",
    "notebook to `features.py` (copied below).\n",
    "\n",
    "On our Feature View we've added four parameters to enable backfilling and\n",
    "ongoing materialization to the online and offline Feature Store:\n",
    "\n",
    "- `online=True`\n",
    "- `offline=True`\n",
    "- `feature_start_time=datetime(2020,1,1)`\n",
    "- `batch_schedule=timedelta(days=1)`\n",
    "\n",
    "The offline and online Feature Stores are used for storing and serving feature values for training and inference. For more information, check out [Tecton Concepts](https://docs.tecton.ai/docs/introduction/tecton-concepts#offline-feature-store).\n",
    "\n",
    "When we apply our changes to a [Live Workspace](https://docs.tecton.ai/docs/introduction/tecton-concepts#workspace), Tecton will automatically kick\n",
    "off jobs to backfill feature data from `feature_start_time`. Frontfill jobs will\n",
    "then run on the defined `batch_schedule`.\n",
    "\n",
    "---\n",
    "\n",
    "##### ‚ÑπÔ∏è **INFO**\n",
    "\n",
    "Besides the new materialization parameters, the code below is exactly the same as our definitions above. No changes are required when moving from interactive development to productionization!\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**features.py**\n",
    "\n",
    "```python\n",
    "from tecton import Entity, BatchSource, FileConfig, batch_feature_view, Aggregation, FeatureService\n",
    "from tecton.types import Field, String, Timestamp, Float64\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "transactions = BatchSource(\n",
    "    name=\"transactions\",\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://mft-porter-data/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# An entity defines the concept we are modeling features for\n",
    "# The join keys will be used to aggregate, join, and retrieve features\n",
    "user = Entity(name=\"user\", join_keys=[\"user_id\"])\n",
    "\n",
    "# We use Pandas to transform the raw data and Tecton aggregations to efficiently and accurately compute metrics across raw events\n",
    "# Feature View decorators contain a wide range of parameters for materializing, cataloging, and monitoring features\n",
    "@batch_feature_view(\n",
    "    description=\"User transaction metrics over 1, 3 and 7 days\",\n",
    "    sources=[transactions],\n",
    "    entities=[user],\n",
    "    mode=\"pandas\",\n",
    "    aggregation_interval=timedelta(days=1),\n",
    "    aggregations=[\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=1)),\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=3)),\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=7)),\n",
    "        Aggregation(function=\"count\", column=\"amount\", time_window=timedelta(days=1)),\n",
    "        Aggregation(function=\"count\", column=\"amount\", time_window=timedelta(days=3)),\n",
    "        Aggregation(function=\"count\", column=\"amount\", time_window=timedelta(days=7)),\n",
    "    ],\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    "    online=True,\n",
    "    offline=True,\n",
    "    feature_start_time=datetime(2020, 1, 1),\n",
    "    batch_schedule=timedelta(days=1),\n",
    ")\n",
    "def user_transaction_metrics(transactions):\n",
    "    return transactions[[\"user_id\", \"timestamp\", \"amount\"]]\n",
    "\n",
    "fraud_detection_feature_service = FeatureService(\n",
    "    name=\"fraud_detection_feature_service\", features=[user_transaction_metrics]\n",
    ")\n",
    "```\n",
    "\n",
    "### 3. Apply your changes to a new workspace\n",
    "\n",
    "Our last step is to login to your organization's Tecton account and apply our\n",
    "repo to a workspace!\n",
    "\n",
    "‚úÖ Run the following commands in your terminal to create a workspace and apply\n",
    "your changes:\n",
    "\n",
    "```bash\n",
    "tecton login [your-org-account-name].tecton.ai\n",
    "tecton workspace create [your-name]-quickstart --live\n",
    "tecton apply\n",
    "```\n",
    "\n",
    "```\n",
    "Using workspace \"[your-name]-quickstart\" on cluster https://explore.tecton.ai\n",
    "‚úÖ Imported 1 Python module from the feature repository\n",
    "‚úÖ Imported 1 Python module from the feature repository\n",
    "‚ö†Ô∏è  Running Tests: No tests found.\n",
    "‚úÖ Collecting local feature declarations\n",
    "‚úÖ Performing server-side feature validation: Initializing.\n",
    " ‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì Plan Start ‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì‚Üì\n",
    "\n",
    "  + Create Batch Data Source\n",
    "    name:           transactions\n",
    "\n",
    "  + Create Entity\n",
    "    name:           user\n",
    "\n",
    "  + Create Transformation\n",
    "    name:           user_transaction_metrics\n",
    "    description:    Trailing average transaction amount over 1, 3 and 7 days\n",
    "\n",
    "  + Create Batch Feature View\n",
    "    name:           user_transaction_metrics\n",
    "    description:    Trailing average transaction amount over 1, 3 and 7 days\n",
    "    materialization: 11 backfills, 1 recurring batch job\n",
    "    > backfill:     10 Backfill jobs 2020-01-01 00:00:00 UTC to 2023-08-16 00:00:00 UTC writing to the Offline Store\n",
    "                    1 Backfill job 2023-08-16 00:00:00 UTC to 2023-08-23 00:00:00 UTC writing to both the Online and Offline Store\n",
    "    > incremental:  1 Recurring Batch job scheduled every 1 day writing to both the Online and Offline Store\n",
    "\n",
    "  + Create Feature Service\n",
    "    name:           fraud_detection_feature_service\n",
    "\n",
    " ‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë Plan End ‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë‚Üë\n",
    " Generated plan ID is 8d01ad78e3194a5dbd3f934f04d71564\n",
    " View your plan in the Web UI: https://explore.tecton.ai/app/[your-name]-quickstart/plan-summary/8d01ad78e3194a5dbd3f934f04d71564\n",
    " ‚ö†Ô∏è  Objects in plan contain warnings.\n",
    "\n",
    "Note: Updates to Feature Services may take up to 60 seconds to be propagated to the real-time feature-serving endpoint.\n",
    "Note: This workspace ([your-name]-quickstart) is a \"Live\" workspace. Applying this plan may result in new materialization jobs which will incur costs. Carefully examine the plan output before applying changes.\n",
    "Are you sure you want to apply this plan to: \"[your-name]-quickstart\"? [y/N]> y\n",
    "üéâ all done!\n",
    "```\n",
    "\n",
    "## üü¢ Check on backfilling status\n",
    "\n",
    "Now that we've applied our features to a live workspace and enabled\n",
    "materialization to the online and offline store, we can check on the status of\n",
    "backfill jobs in the Tecton Web UI.\n",
    "\n",
    "This can be found at the following URL (replace `[your-org-account-name]` and `[your-workspace-name]` with the appropriate values):\n",
    "\n",
    "[https://[your-org-account-name].tecton.ai/app/repo/[your-workspace-name]/features/user_transaction_metrics/materialization](https://[your-org-account-name].tecton.ai/app/repo/[your-workspace-name]/features/user_transaction_metrics/materialization)\n",
    "\n",
    "If you are using `explore.tecton.ai`, the URL will be:\n",
    "[https://explore.tecton.ai/app/repo/prod/features/user_transaction_metrics/materialization](https://explore.tecton.ai/app/repo/prod/features/user_transaction_metrics/materialization)\n",
    "\n",
    "Once the backfill jobs have completed, we can fetch feature values online!\n",
    "\n",
    "## ‚ö°Ô∏è Create a function to retrieve features from Tecton's HTTP API\n",
    "\n",
    "Now let's use Tecton's HTTP API to retrieve features at low latency.\n",
    "\n",
    "To do this, you will first need to create a new Service Account and give it\n",
    "access to read features from your workspace.\n",
    "\n",
    "‚úÖ Head to the following URL to create a new service account (replace \"explore\" with your organization's account name in the URL as necessary). Be sure to save the API key!\n",
    "\n",
    "[https://explore.tecton.ai/app/settings/accounts-and-access/service-accounts?create-service-account=true](https://explore.tecton.ai/app/settings/accounts-and-access/service-accounts?create-service-account=true)\n",
    "\n",
    "‚úÖ If you are using `explore.tecton.ai`, this account will automatically be given the necessary privileges to read features from the \"prod\" workspace. Otherwise, you should give the service account access to read features from your newly created workspace by following these steps:\n",
    "\n",
    "1. Navigate to the Service Account page by clicking on your new service account in the list at the URL above\n",
    "2. Click on \"Assign Workspace Access\"\n",
    "3. Select your workspace and give the service account the \"Consumer\" role\n",
    "\n",
    "‚úÖ Copy the generated API key into the code snippet below where it says `your-api-key`. Also be sure to replace the workspace and account name with your newly created workspace name and account name if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "\n",
    "\n",
    "def get_online_feature_data(user_id):\n",
    "    TECTON_API_KEY = \"your-api-key\"  # replace with your API key\n",
    "    WORKSPACE_NAME = \"prod\"  # replace with your new workspace name if needed\n",
    "    ACCOUNT_URL = \"demo-pangolin.tecton.ai\"  # replace with your org account URL if needed\n",
    "\n",
    "    headers = {\"Authorization\": \"Tecton-key \" + TECTON_API_KEY}\n",
    "\n",
    "    request_data = f\"\"\"{{\n",
    "        \"params\": {{\n",
    "            \"feature_service_name\": \"fraud_detection_feature_service\",\n",
    "            \"join_key_map\": {{\"user_id\": \"{user_id}\"}},\n",
    "            \"metadata_options\": {{\"include_names\": true}},\n",
    "            \"workspace_name\": \"{WORKSPACE_NAME}\"\n",
    "        }}\n",
    "    }}\"\"\"\n",
    "\n",
    "    online_feature_data = requests.request(\n",
    "        method=\"POST\",\n",
    "        headers=headers,\n",
    "        url=f\"https://{ACCOUNT_URL}/api/v1/feature-service/get-features\",\n",
    "        data=request_data,\n",
    "    )\n",
    "\n",
    "    online_feature_data_json = json.loads(online_feature_data.text)\n",
    "\n",
    "    return online_feature_data_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use our function to retrieve features at low latency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'features': ['1', '3', '8', 28.26, 317.61, 210.35125]}\n"
     ]
    }
   ],
   "source": [
    "user_id = \"user_1990251765\"\n",
    "\n",
    "feature_data = get_online_feature_data(user_id)\n",
    "\n",
    "if \"result\" not in feature_data:\n",
    "    print(\"Error: Either your feature data is not done materializing, or you have an incorrect API key above.\")\n",
    "else:\n",
    "    print(feature_data[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Create a function to make a prediction given feature data\n",
    "\n",
    "Now that we can fetch feature data online, let's create a function that takes a\n",
    "feature vector and runs model inference to get a fraud prediction.\n",
    "\n",
    "---\n",
    "\n",
    "##### ‚ÑπÔ∏è **INFO**\n",
    "\n",
    "Typically you'd instead use a model serving API that is hosting your model. Here we run inference directly in our notebook for simplicity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_prediction_from_model(feature_data):\n",
    "    columns = [f[\"name\"].replace(\".\", \"__\") for f in feature_data[\"metadata\"][\"features\"]]\n",
    "    data = [feature_data[\"result\"][\"features\"]]\n",
    "\n",
    "    features = pd.DataFrame(data, columns=columns)[X.columns]\n",
    "\n",
    "    return model.predict(features)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ú® Run inference using features from Tecton\n",
    "\n",
    "Let's combine these functions and run inference!\n",
    "\n",
    "We can fetch our online features from Tecton, call our inference function, and\n",
    "get a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "user_id = \"user_1990251765\"\n",
    "\n",
    "online_feature_data = get_online_feature_data(user_id)\n",
    "prediction = get_prediction_from_model(online_feature_data)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Create a function to evaluate a user transaction and accept or reject it\n",
    "\n",
    "Our final step is to use our new fraud prediction pipeline to make decisions and\n",
    "take action in our application.\n",
    "\n",
    "In the function below we use simple business logic to decide whether to accept\n",
    "or reject a transaction based on our predicted fraud score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_transaction(user_id):\n",
    "    online_feature_data = get_online_feature_data(user_id)\n",
    "    is_predicted_fraud = get_prediction_from_model(online_feature_data)\n",
    "\n",
    "    if is_predicted_fraud == 0:\n",
    "        return \"Transaction accepted.\"\n",
    "    else:\n",
    "        return \"Transaction denied.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí∞ Evaluate a transaction\n",
    "\n",
    "Put it all together and we have a single online, low-latency decision API for\n",
    "our application. Try it out below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transaction accepted.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_transaction(\"user_1990251765\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚≠êÔ∏è Conclusion\n",
    "\n",
    "In this tutorial, we were able to quickly make an end to end real-time fraud\n",
    "detection application using features built in Tecton.\n",
    "\n",
    "We tested our features, built training data sets, productionized features with\n",
    "engineering best practices, retrieved features online, and made decisions in\n",
    "real time!\n",
    "\n",
    "But Tecton can do so much more:\n",
    "\n",
    "- streaming features\n",
    "- real-time features\n",
    "- monitoring\n",
    "- unit testing\n",
    "- cataloging and discovery\n",
    "- access controls\n",
    "- cost management\n",
    "- rules engines\n",
    "\n",
    "...and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
