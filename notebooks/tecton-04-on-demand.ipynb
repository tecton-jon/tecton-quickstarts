{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⏱️ Building On-Demand Features\n",
    "\n",
    "Many critical features for real-time models can only be calculated at the time of a request, either because:\n",
    "\n",
    "1. They require data that is only available at request time (e.g. a user's current location)\n",
    "2. They can't efficiently be pre-computed (e.g. computing the embedding similarity between all possible users)\n",
    "\n",
    "Running transformations at request time can also be useful for:\n",
    "\n",
    "1. Post-processing feature data (example: imputing null values)\n",
    "2. Running additional transformations after Tecton-managed aggregations\n",
    "3. Defining new features without needing to rematerialize Feature Store data\n",
    "\n",
    "For more details, see [On-Demand Feature Views](https://docs.tecton.ai/docs/defining-features/feature-views/on-demand-feature-view).\n",
    "\n",
    "This is where \"On-Demand\" features come in. In Tecton, an On-Demand Feature View let's you calculate features at the time of a request, using either data passed in with the request or pre-computed batch and stream features.\n",
    "\n",
    "This tutorial will show how you can develop, test, and productionize on-demand features for real-time models. This tutorial is centered around a fraud detection use case, where we need to predict in real-time whether a transaction that a user is making is fraudulent.\n",
    "\n",
    "---\n",
    "##### 🗒️ **NOTE** \n",
    "\n",
    "This tutorial assumes some basic familiarity with Tecton. If you are new to Tecton, we recommend first checking out Building a Production AI Application with Tecton which walks through an end-to-end journey of building a real-time ML application with Tecton.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ Install Pre-Reqs\n",
    "\n",
    "First things first, let's install the Tecton SDK and other libraries used by this tutorial (we recommend in a virtual environment) using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install 'tecton[rift]' gcsfs s3fs --quiet --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Log in to Tecton\n",
    "\n",
    "Next we will authenticate with your organization's Tecton account and import libraries we will need.\n",
    "\n",
    "*Note: You need to press `enter` after pasting in your authentication code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already logged in to https://demo-pangolin.tecton.ai as UserProfile(name='Jonathan Varley', email='jon@tecton.ai', id='00ut35dahebreB27E357'). To switch users, run `tecton.logout` then `tecton.login`\n"
     ]
    }
   ],
   "source": [
    "import tecton\n",
    "\n",
    "tecton.login(\"demo-pangolin.tecton.ai\")  # replace with your URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then run some basic imports and setup that we will use later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 0.9.12\n",
      "Git Commit: 7b1322f6df430b497a8fd0535186da3bf3ee6612\n",
      "Build Datetime: 2024-06-25T14:37:08\n"
     ]
    }
   ],
   "source": [
    "from tecton import *\n",
    "from tecton.types import *\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "tecton.set_validation_mode(\"auto\")\n",
    "tecton.conf.set(\"TECTON_OFFLINE_RETRIEVAL_COMPUTE_MODE\", \"rift\")\n",
    "\n",
    "tecton.version.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👩‍💻 Create an on-demand feature that leverages request data\n",
    "\n",
    "Let's say that for our fraud detection model, we want to be able to leverage information about the user's current transaction that we are evaluating. We only have access to that information at the time of evaluation so any features derived from current transaction information need to be computed in real-time.\n",
    "\n",
    "On-Demand Feature Views are able to leverage real-time request data for building features. In this case, we will do a very simple check to see if the current transaction amount is over $1000. This is a pretty basic feature, but in the next section we will look at how to make it better!\n",
    "\n",
    "To define an on-demand feature that leverages request data, we first define a Request Source. The Request Source specifies the expected schema for the data that will be passed in with the request.\n",
    "\n",
    "---\n",
    "NOTE: When using mode='python' the inputs and outputs of the On-Demand Feature View are dictionaries.\n",
    "\n",
    "For more information on modes in On Demand Feature Views see [On-Demand Feature Views](https://docs.tecton.ai/docs/defining-features/feature-views/on-demand-feature-view)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton import StreamSource, PushConfig, FileConfig\n",
    "from tecton.types import Field, String, Timestamp, Float64\n",
    "\n",
    "\n",
    "transactions_stream = StreamSource(\n",
    "    name=\"transactions_stream\",\n",
    "    stream_config=PushConfig(),\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://mft-porter-data/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined our feature, we can test it out with some mock data using `.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_request = RequestSource(schema=[Field(\"amount\", Float64)])\n",
    "\n",
    "\n",
    "@on_demand_feature_view(\n",
    "    sources=[transaction_request],\n",
    "    mode=\"python\",\n",
    "    schema=[Field(\"transaction_amount_is_high\", Bool)],\n",
    ")\n",
    "def transaction_amount_is_high(request):\n",
    "    return {\"transaction_amount_is_high\": request[\"amount\"] > 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnDemandFeatureView 'transaction_amount_is_high': Validating 1 dependency.\n",
      "    Transformation 'transaction_amount_is_high': Successfully validated.\n",
      "OnDemandFeatureView 'transaction_amount_is_high': Successfully validated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'transaction_amount_is_high': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\"request\": {\"amount\": 182.4}}\n",
    "\n",
    "transaction_amount_is_high.run_transformation(input_data=input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔗 Create an on-demand feature that leverages request data and other features\n",
    "This feature is okay, but wouldn't it be much better if we could compare the transaction amount to the user's historical average?\n",
    "\n",
    "On-Demand Feature Views also have the ability to depend on Batch and Stream Feature Views as input data sources. We can use this capability to improve our feature. Let's take a look.\n",
    "\n",
    "First we will create a Batch Feature View that computes the user's 1-year average transaction amount. Then we will add this as a source in a new On-Demand Feature View with an updated feature transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_batch = BatchSource(\n",
    "    name=\"transactions_batch\",\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://mft-porter-data/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "user = Entity(name=\"user\", join_keys=[\"user_id\"])\n",
    "\n",
    "\n",
    "@batch_feature_view(\n",
    "    sources=[transactions_batch],\n",
    "    entities=[user],\n",
    "    mode=\"pandas\",\n",
    "    aggregation_interval=timedelta(days=1),\n",
    "    aggregations=[\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=365), name=\"yearly_average\"),\n",
    "    ],\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    ")\n",
    "def user_transaction_averages(transactions):\n",
    "    return transactions[[\"user_id\", \"timestamp\", \"amount\"]]\n",
    "\n",
    "\n",
    "transaction_request = RequestSource(schema=[Field(\"amount\", Float64)])\n",
    "\n",
    "\n",
    "@on_demand_feature_view(\n",
    "    sources=[transaction_request, user_transaction_averages],\n",
    "    mode=\"python\",\n",
    "    schema=[Field(\"transaction_amount_is_higher_than_average\", Bool)],\n",
    ")\n",
    "def transaction_amount_is_higher_than_average(transaction_request, user_transaction_averages):\n",
    "    amount_mean = user_transaction_averages[\"yearly_average\"] or 0\n",
    "    return {\"transaction_amount_is_higher_than_average\": transaction_request[\"amount\"] > amount_mean}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again test our new feature using .run() and passing in example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnDemandFeatureView 'transaction_amount_is_higher_than_average': Validating 2 dependencies.\n",
      "    Transformation 'transaction_amount_is_higher_than_average': Successfully validated.\n",
      "    BatchFeatureView 'user_transaction_averages': Validating 3 dependencies.\n",
      "        BatchSource 'transactions_batch': Successfully validated.\n",
      "        Entity 'user': Successfully validated.\n",
      "        Transformation 'user_transaction_averages': Successfully validated.\n",
      "    BatchFeatureView 'user_transaction_averages': Successfully validated.\n",
      "OnDemandFeatureView 'transaction_amount_is_higher_than_average': Successfully validated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'transaction_amount_is_higher_than_average': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\"transaction_request\": {\"amount\": 182.4}, \"user_transaction_averages\": {\"yearly_average\": 33.46}}\n",
    "\n",
    "transaction_amount_is_higher_than_average.run_transformation(input_data=input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that this feature looks to be doing what we want, let's see how we can generate training data with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧮 Generating Training Data with On-Demand Features\n",
    "When generating training datasets for on-demand features, Tecton uses the exact same transformation logic as it does online to eliminate online/offline skew.\n",
    "\n",
    "The Python function you defined will be executed as a UDF on the training data set.\n",
    "\n",
    "To see this in action, we will first load up a set of historical training events.\n",
    "\n",
    "---\n",
    "\n",
    "##### 🗒️ **NOTE**\n",
    "\n",
    "Tecton expects that any request data passed in online is present in the set of historical training events. In our example below, this is represented by the amount column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1990251765</td>\n",
       "      <td>2020-01-01 00:27:59.442071</td>\n",
       "      <td>28.86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1284832379</td>\n",
       "      <td>2020-01-01 01:11:01.384867</td>\n",
       "      <td>20.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_9979340926</td>\n",
       "      <td>2020-01-01 01:20:59.084788</td>\n",
       "      <td>98.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_8096819426</td>\n",
       "      <td>2020-01-01 01:22:08.889972</td>\n",
       "      <td>97.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_8096819426</td>\n",
       "      <td>2020-01-01 01:49:01.356931</td>\n",
       "      <td>27.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id                  timestamp  amount  is_fraud\n",
       "0  user_1990251765 2020-01-01 00:27:59.442071   28.86         0\n",
       "1  user_1284832379 2020-01-01 01:11:01.384867   20.46         0\n",
       "2  user_9979340926 2020-01-01 01:20:59.084788   98.39         0\n",
       "3  user_8096819426 2020-01-01 01:22:08.889972   97.74         0\n",
       "4  user_8096819426 2020-01-01 01:49:01.356931   27.53         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve our dataset of historical transaction data\n",
    "transactions_df = pd.read_parquet(\"s3://mft-porter-data/tutorials/transactions.pq\", storage_options={\"anon\": True})\n",
    "\n",
    "# Retrieve our dataset of labels containing transaction_id and is_fraud (set to 1 if the transaction is fraudulent or 0 otherwise)\n",
    "training_labels = pd.read_parquet(\"s3://mft-porter-data/tutorials/labels.pq\", storage_options={\"anon\": True})\n",
    "\n",
    "# Join our label dataset to our transaction data to produce a list of training events\n",
    "training_events = training_labels.merge(transactions_df, on=[\"transaction_id\"], how=\"left\")[\n",
    "    [\"user_id\", \"timestamp\", \"amount\", \"is_fraud\"]\n",
    "]\n",
    "\n",
    "display(training_events.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add our On-Demand Feature View to a Feature Service and generate training data for these historical events.\n",
    "\n",
    "---\n",
    "\n",
    "##### 🗒️ **NOTE**\n",
    "\n",
    "---\n",
    "\n",
    "We included the dependent Batch Feature View in the Feature Service as well to visualize the data better, but it is not necessary to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureService 'fraud_detection_feature_service': Successfully validated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>user_transaction_averages__yearly_average</th>\n",
       "      <th>transaction_amount_is_higher_than_average__transaction_amount_is_higher_than_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_7661963940</td>\n",
       "      <td>2020-01-03 05:27:27.815179</td>\n",
       "      <td>32.36</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_7661963940</td>\n",
       "      <td>2020-01-03 18:04:50.511544</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_7661963940</td>\n",
       "      <td>2020-01-04 19:23:24.779383</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0</td>\n",
       "      <td>16.44</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_7661963940</td>\n",
       "      <td>2020-01-04 10:30:56.768177</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0</td>\n",
       "      <td>16.44</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_7661963940</td>\n",
       "      <td>2020-01-04 02:51:07.950199</td>\n",
       "      <td>81.76</td>\n",
       "      <td>0</td>\n",
       "      <td>16.44</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id                  timestamp  amount  is_fraud  \\\n",
       "0  user_7661963940 2020-01-03 05:27:27.815179   32.36         0   \n",
       "1  user_7661963940 2020-01-03 18:04:50.511544    0.52         0   \n",
       "2  user_7661963940 2020-01-04 19:23:24.779383    8.26         0   \n",
       "3  user_7661963940 2020-01-04 10:30:56.768177    4.60         0   \n",
       "4  user_7661963940 2020-01-04 02:51:07.950199   81.76         0   \n",
       "\n",
       "  user_transaction_averages__yearly_average  \\\n",
       "0                                      None   \n",
       "1                                      None   \n",
       "2                                     16.44   \n",
       "3                                     16.44   \n",
       "4                                     16.44   \n",
       "\n",
       "   transaction_amount_is_higher_than_average__transaction_amount_is_higher_than_average  \n",
       "0                                               True                                     \n",
       "1                                               True                                     \n",
       "2                                              False                                     \n",
       "3                                              False                                     \n",
       "4                                               True                                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tecton import FeatureService\n",
    "\n",
    "\n",
    "fraud_detection_feature_service = FeatureService(\n",
    "    name=\"fraud_detection_feature_service\",\n",
    "    features=[user_transaction_averages, transaction_amount_is_higher_than_average],\n",
    ")\n",
    "\n",
    "training_data = fraud_detection_feature_service.get_features_for_events(training_events).to_pandas()\n",
    "display(training_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this training data set to train an accurate model with our new feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Run on-demand features in production\n",
    "Once we are happy with our On-Demand Feature View we can copy the definitions into our Feature Repository and apply our changes to a live workspace using the Tecton CLI.\n",
    "\n",
    "---\n",
    "##### 🗒️ **NOTE**\n",
    "\n",
    "For more information on working with Feature Repositories or applying changes to workspaces, check out the Quick Start tutorial or Feature Development Workflow pages.\n",
    "\n",
    "---\n",
    "\n",
    "We've also included the Batch Feature View dependency and the Feature Service in the file below.\n",
    "\n",
    "**feature_repo.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton import *\n",
    "from tecton.types import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "transactions_batch = BatchSource(\n",
    "    name=\"transactions_batch\",\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://mft-porter-data/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "user = Entity(name=\"user\", join_keys=[\"user_id\"])\n",
    "\n",
    "\n",
    "@batch_feature_view(\n",
    "    sources=[transactions_batch],\n",
    "    entities=[user],\n",
    "    mode=\"pandas\",\n",
    "    aggregation_interval=timedelta(days=1),\n",
    "    aggregations=[\n",
    "        Aggregation(function=\"mean\", column=\"amount\", time_window=timedelta(days=365), name=\"yearly_average\"),\n",
    "    ],\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    "    online=True,\n",
    "    offline=True,\n",
    "    feature_start_time=datetime(2023, 1, 1),\n",
    ")\n",
    "def user_transaction_averages(transactions):\n",
    "    return transactions[[\"user_id\", \"timestamp\", \"amount\"]]\n",
    "\n",
    "\n",
    "transaction_request = RequestSource(schema=[Field(\"amount\", Float64)])\n",
    "\n",
    "\n",
    "@on_demand_feature_view(\n",
    "    sources=[transaction_request, user_transaction_averages],\n",
    "    mode=\"python\",\n",
    "    schema=[Field(\"transaction_amount_is_higher_than_average\", Bool)],\n",
    ")\n",
    "def transaction_amount_is_higher_than_average(transaction_request, user_transaction_averages):\n",
    "    amount_mean = user_transaction_averages[\"yearly_average\"] or 0\n",
    "    return {\"transaction_amount_is_higher_than_average\": transaction_request[\"amount\"] > amount_mean}\n",
    "\n",
    "\n",
    "fraud_detection_feature_service = FeatureService(\n",
    "    name=\"fraud_detection_feature_service\",\n",
    "    features=[user_transaction_averages, transaction_amount_is_higher_than_average],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Run the following commands in your terminal to create a live workspace and apply your changes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tecton login demo-pangolin.tecton.ai\n",
    "tecton workspace create --live [my-live-workspace]\n",
    "tecton apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡️ Retrieve real-time features\n",
    "Now that our On-Demand Feature View is productionized, we can use it to compute features in real-time!\n",
    "\n",
    "IMPORTANT: This step requires generating and setting a Service Account and giving it permissions to read from this workspace.\n",
    "\n",
    "✅ Head to the following URL to create a new service account (replace \"explore\" with your organization's account name in the URL as necessary). Be sure to save the API key!\n",
    "\n",
    "https://explore.tecton.ai/app/settings/accounts-and-access/service-accounts?create-service-account=true\n",
    "\n",
    "✅ Next, you should give the service account access to read features from your newly created workspace by following these steps:\n",
    "\n",
    "Navigate to the Service Account page by clicking on your new service account in the list at the URL above\n",
    "Click on \"Assign Workspace Access\"\n",
    "Select your workspace and give the service account the \"Consumer\" role\n",
    "✅ Copy the generated API key into the code snippet below where it says your-api-key. Also be sure to replace the workspace name with your newly created workspace name.\n",
    "\n",
    "In the code below, we will retrieve a feature vector from our Feature Service, while passing in the necessary request data (the current transaction amount).\n",
    "\n",
    "Tecton will use our python transformation to compute features in real-time using that request data, as well as the historical transaction average, retrieved from the online store.\n",
    "\n",
    "Be sure to replace your-api-key with the key you generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully set credentials.\n",
      "{'transaction_amount_is_higher_than_average.transaction_amount_is_higher_than_average': False,\n",
      " 'user_credit_card_issuer.credit_card_issuer': 'Visa',\n",
      " 'user_transaction_amount_totals.amount_sum_1h_continuous': None,\n",
      " 'user_transaction_amount_totals.amount_sum_1m_continuous': None,\n",
      " 'user_transaction_amount_totals.amount_sum_30d_continuous': 13490.520000000002,\n",
      " 'user_transaction_metrics.amount_count_1d_1d': 2,\n",
      " 'user_transaction_metrics.amount_count_3d_1d': 4,\n",
      " 'user_transaction_metrics.amount_count_7d_1d': 13,\n",
      " 'user_transaction_metrics.amount_mean_1d_1d': 490.71,\n",
      " 'user_transaction_metrics.amount_mean_3d_1d': 445.78499999999997,\n",
      " 'user_transaction_metrics.amount_mean_7d_1d': 868.3153846153847}\n"
     ]
    }
   ],
   "source": [
    "# Use your API key generated in the step above\n",
    "TECTON_API_KEY = \"your-api-key\"  # replace with your API key\n",
    "WORKSPACE_NAME = \"prod\"  # replace with your new workspace name if needed\n",
    "\n",
    "tecton.set_credentials(tecton_api_key=TECTON_API_KEY)\n",
    "\n",
    "ws = tecton.get_workspace(WORKSPACE_NAME)\n",
    "fraud_detection_feature_service = ws.get_feature_service(\"fraud_detection_feature_service:v2\")\n",
    "\n",
    "join_keys = {\"user_id\": \"user_7661963940\"}\n",
    "request_data = {\"amount\": 72.06}\n",
    "\n",
    "features = fraud_detection_feature_service.get_online_features(join_keys=join_keys, request_data=request_data)\n",
    "\n",
    "pprint(features.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIP: The .get_online_features() method makes it easy to push events from a notebook. For best performance in production, we recommend reading directly from the REST API or using our Python Client Library\n",
    "\n",
    "## ⭐️ Conclusion\n",
    "Nice work! Now you've successfully productionized a true real-time feature that could only be computed at request time all using simple Python.\n",
    "\n",
    "But that's just the start of what Tecton can do. Check out [Feature Design Patterns](https://docs.tecton.ai/docs/defining-features/feature-views/feature-design-patterns) to see all the types of features you can build using Batch, Stream, and On-Demand Feature Views."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
