{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ö°Ô∏è Building Streaming Features\n",
    "\n",
    "---\n",
    "\n",
    "Real-time data can make all the difference for real-time models, but leveraging\n",
    "it can be quite the challenge.\n",
    "\n",
    "With Tecton you can build millisecond fresh features using plain Python and\n",
    "without any complex streaming infrastructure! Best of all, you can test it all\n",
    "locally and iterate in a notebook to quickly train better models that operate\n",
    "consistently online and offline.\n",
    "\n",
    "---\n",
    "\n",
    "In this tutorial we will:\n",
    "\n",
    "1. Create a streaming data source\n",
    "2. Define and test streaming features\n",
    "3. Query data online and offline\n",
    "\n",
    "## ‚öôÔ∏è Install Pre-Reqs\n",
    "\n",
    "First things first, let's install the Tecton SDK and other libraries used in this tutorial by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install 'tecton[rift]' gcsfs s3fs --quiet --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Log in to Tecton\n",
    "\n",
    "Next we will authenticate with your organization's Tecton account and import libraries we will need.\n",
    "\n",
    "*Note: You need to press `enter` after pasting in your authentication code.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already logged in to https://demo-pangolin.tecton.ai as UserProfile(name='Jonathan Varley', email='jon@tecton.ai', id='00ut35dahebreB27E357'). To switch users, run `tecton.logout` then `tecton.login`\n",
      "Version: 0.9.12\n",
      "Git Commit: 7b1322f6df430b497a8fd0535186da3bf3ee6612\n",
      "Build Datetime: 2024-06-25T14:37:08\n"
     ]
    }
   ],
   "source": [
    "import tecton\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "import random, string\n",
    "\n",
    "tecton.login(\"demo-pangolin.tecton.ai\")  # replace with your URL\n",
    "\n",
    "tecton.set_validation_mode(\"auto\")\n",
    "tecton.conf.set(\"TECTON_OFFLINE_RETRIEVAL_COMPUTE_MODE\", \"rift\")\n",
    "\n",
    "tecton.version.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to build!\n",
    "\n",
    "## üåä Create a Stream Source for ingesting real-time data\n",
    "\n",
    "First, let's define a local Stream Source that supports\n",
    "[ingesting real-time data](https://docs.tecton.ai/docs/defining-features/data-sources/creating-a-data-source/creating-and-testing-a-push-source).\n",
    "Once productionized, this will give us an online HTTP endpoint to push events to\n",
    "in real-time which Tecton will then transform into features for online\n",
    "inference.\n",
    "\n",
    "As part of our Stream Source, we also register a historical log of the stream\n",
    "via the `batch_config` parameter. Tecton uses this historical log for backfills\n",
    "and offline development.\n",
    "\n",
    "---\n",
    "\n",
    "##### üí° **TIP**\n",
    "\n",
    "Alternatively, you can have Tecton maintain this historical log for you! Simply add the `log_offline=True` parameter to the `PushConfig` and omit the `batch_config`. With this setup Tecton will log all ingested events and use those to backfill any features that use this source.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton import StreamSource, PushConfig, FileConfig\n",
    "from tecton.types import Field, String, Timestamp, Float64\n",
    "\n",
    "\n",
    "transactions_stream = StreamSource(\n",
    "    name=\"transactions_stream\",\n",
    "    stream_config=PushConfig(),\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://mft-porter-data/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Test the new Stream Source\n",
    "\n",
    "We can pull a range of offline data from a Stream Source's historical event log\n",
    "using `get_dataframe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamSource 'transactions_stream': Deriving schema.\n",
      "StreamSource 'transactions_stream': Successfully validated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>merchant</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-05-01 00:04:37.805216</td>\n",
       "      <td>user_8041734544</td>\n",
       "      <td>8e261b034cf32c445ca6e66f648f88d6</td>\n",
       "      <td>LensCrafters</td>\n",
       "      <td>84.660493</td>\n",
       "      <td>162.841237</td>\n",
       "      <td>75.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-05-01 00:18:15.088549</td>\n",
       "      <td>user_6971829885</td>\n",
       "      <td>7ff11a5b0167b2bd66f36f2fd2de2fa5</td>\n",
       "      <td>Cabela's</td>\n",
       "      <td>82.088167</td>\n",
       "      <td>-103.099069</td>\n",
       "      <td>11.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-05-01 00:24:03.157971</td>\n",
       "      <td>user_9619731767</td>\n",
       "      <td>7c890265fe39dd25ced53d873fd0eb73</td>\n",
       "      <td>Forever 21</td>\n",
       "      <td>-23.561850</td>\n",
       "      <td>102.008712</td>\n",
       "      <td>569.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-05-01 00:31:32.125634</td>\n",
       "      <td>user_4856370219</td>\n",
       "      <td>a92220b1702b9e21e80cf9a005e6ae2a</td>\n",
       "      <td>Sonic Automotive</td>\n",
       "      <td>1.146113</td>\n",
       "      <td>-53.365226</td>\n",
       "      <td>1.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-05-01 00:32:47.850232</td>\n",
       "      <td>user_4133774204</td>\n",
       "      <td>e2cabe6ef03ea6183df8277962262bce</td>\n",
       "      <td>Value City Furniture</td>\n",
       "      <td>-2.152083</td>\n",
       "      <td>-26.665665</td>\n",
       "      <td>61.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp          user_id  \\\n",
       "0 2023-05-01 00:04:37.805216  user_8041734544   \n",
       "1 2023-05-01 00:18:15.088549  user_6971829885   \n",
       "2 2023-05-01 00:24:03.157971  user_9619731767   \n",
       "3 2023-05-01 00:31:32.125634  user_4856370219   \n",
       "4 2023-05-01 00:32:47.850232  user_4133774204   \n",
       "\n",
       "                     transaction_id              merchant  merch_lat  \\\n",
       "0  8e261b034cf32c445ca6e66f648f88d6          LensCrafters  84.660493   \n",
       "1  7ff11a5b0167b2bd66f36f2fd2de2fa5              Cabela's  82.088167   \n",
       "2  7c890265fe39dd25ced53d873fd0eb73            Forever 21 -23.561850   \n",
       "3  a92220b1702b9e21e80cf9a005e6ae2a      Sonic Automotive   1.146113   \n",
       "4  e2cabe6ef03ea6183df8277962262bce  Value City Furniture  -2.152083   \n",
       "\n",
       "   merch_long  amount  \n",
       "0  162.841237   75.42  \n",
       "1 -103.099069   11.12  \n",
       "2  102.008712  569.99  \n",
       "3  -53.365226    1.51  \n",
       "4  -26.665665   61.67  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = datetime(2023, 5, 1)\n",
    "end = datetime(2023, 8, 1)\n",
    "\n",
    "df = transactions_stream.get_dataframe(start, end).to_pandas()\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üë©‚Äçüíª Define and test streaming features locally\n",
    "\n",
    "Now that we have a Stream Source defined, we are ready to create some features.\n",
    "\n",
    "Let's use this data source to create the following 3 features:\n",
    "\n",
    "- A user's total transaction amount in the last 1 minute\n",
    "- A user's total transaction amount in the last 1 hour\n",
    "- A user's total transaction amount in the last 30 days\n",
    "\n",
    "To build these features, we will define a Stream Feature View that consumes from\n",
    "our `transactions` Stream Source.\n",
    "\n",
    "The Stream Feature View transformation operates on events in a Pandas Dataframe\n",
    "and can do any arbitrary projections, filters, or expressions as needed. It's\n",
    "just Python!\n",
    "\n",
    "---\n",
    "\n",
    "##### ‚ÑπÔ∏è **INFO**\n",
    "\n",
    "The Python transformation runs *before* the aggregations so you can transform data as needed before it is aggregated.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tecton import Entity, stream_feature_view, Aggregation\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "user = Entity(name=\"user\", join_keys=[\"user_id\"])\n",
    "\n",
    "\n",
    "@stream_feature_view(\n",
    "    source=transactions_stream,\n",
    "    entities=[user],\n",
    "    mode=\"pandas\",\n",
    "    aggregations=[\n",
    "        Aggregation(function=\"sum\", column=\"amount\", time_window=timedelta(minutes=1)),\n",
    "        Aggregation(function=\"sum\", column=\"amount\", time_window=timedelta(hours=1)),\n",
    "        Aggregation(function=\"sum\", column=\"amount\", time_window=timedelta(days=30)),\n",
    "    ],\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    ")\n",
    "def user_transaction_amount_totals(transactions_stream):\n",
    "    return transactions_stream[[\"user_id\", \"timestamp\", \"amount\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Test features interactively\n",
    "\n",
    "Now that we've defined and validated our Feature View, we can use\n",
    "`get_features_in_range` to produce a range of feature values and check out the\n",
    "feature data.\n",
    "\n",
    "---\n",
    "\n",
    "##### ‚ÑπÔ∏è **INFO**\n",
    "\n",
    "These features are calculated against the Stream Source's historical event log.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamFeatureView 'user_transaction_amount_totals': Validating 2 of 3 dependencies. (1 already validated)\n",
      "    Entity 'user': Successfully validated.\n",
      "    Transformation 'user_transaction_amount_totals': Successfully validated.\n",
      "StreamFeatureView 'user_transaction_amount_totals': Successfully validated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>amount_sum_1m_continuous</th>\n",
       "      <th>amount_sum_1h_continuous</th>\n",
       "      <th>amount_sum_30d_continuous</th>\n",
       "      <th>_valid_to</th>\n",
       "      <th>_valid_from</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_8096819426</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>5747.77</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>2022-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2210887384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2198.80</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>2022-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_8096819426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.32</td>\n",
       "      <td>5811.35</td>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>2022-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_1990251765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7077.24</td>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>2022-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_1997016327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6963.97</td>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>2022-01-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id  amount_sum_1m_continuous  amount_sum_1h_continuous  \\\n",
       "0  user_8096819426                      0.02                      0.02   \n",
       "1  user_2210887384                       NaN                      1.72   \n",
       "2  user_8096819426                       NaN                     52.32   \n",
       "3  user_1990251765                       NaN                       NaN   \n",
       "4  user_1997016327                       NaN                       NaN   \n",
       "\n",
       "   amount_sum_30d_continuous  _valid_to _valid_from  \n",
       "0                    5747.77 2022-01-27  2022-01-26  \n",
       "1                    2198.80 2022-01-04  2022-01-03  \n",
       "2                    5811.35 2022-01-28  2022-01-27  \n",
       "3                    7077.24 2022-01-15  2022-01-14  \n",
       "4                    6963.97 2022-01-18  2022-01-17  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = datetime(2022, 1, 1)\n",
    "end = datetime(2022, 2, 1)\n",
    "\n",
    "df = user_transaction_amount_totals.get_features_in_range(start_time=start, end_time=end).to_pandas()\n",
    "\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Generate training data\n",
    "\n",
    "We can also include our new feature in a Feature Service and generate historical\n",
    "training data for a set of training events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeatureService 'fraud_detection_feature_service_streaming': Successfully validated.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>amount</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>user_transaction_amount_totals__amount_sum_1m_continuous</th>\n",
       "      <th>user_transaction_amount_totals__amount_sum_1h_continuous</th>\n",
       "      <th>user_transaction_amount_totals__amount_sum_30d_continuous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>user_4063572189</td>\n",
       "      <td>2022-07-16 17:45:59.391545</td>\n",
       "      <td>59.44</td>\n",
       "      <td>0</td>\n",
       "      <td>59.44</td>\n",
       "      <td>59.44</td>\n",
       "      <td>3215.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64940</th>\n",
       "      <td>user_1997016327</td>\n",
       "      <td>2022-10-01 08:00:59.197635</td>\n",
       "      <td>79.60</td>\n",
       "      <td>0</td>\n",
       "      <td>79.60</td>\n",
       "      <td>79.60</td>\n",
       "      <td>3790.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17451</th>\n",
       "      <td>user_1733657082</td>\n",
       "      <td>2023-02-16 20:22:57.906245</td>\n",
       "      <td>776.82</td>\n",
       "      <td>0</td>\n",
       "      <td>776.82</td>\n",
       "      <td>776.82</td>\n",
       "      <td>6538.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29398</th>\n",
       "      <td>user_7921570811</td>\n",
       "      <td>2020-03-08 14:37:05.027691</td>\n",
       "      <td>472.46</td>\n",
       "      <td>0</td>\n",
       "      <td>472.46</td>\n",
       "      <td>472.46</td>\n",
       "      <td>3991.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58685</th>\n",
       "      <td>user_9757807451</td>\n",
       "      <td>2024-02-19 18:09:45.246353</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1.08</td>\n",
       "      <td>1.08</td>\n",
       "      <td>6020.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id                  timestamp  amount  is_fraud  \\\n",
       "2726   user_4063572189 2022-07-16 17:45:59.391545   59.44         0   \n",
       "64940  user_1997016327 2022-10-01 08:00:59.197635   79.60         0   \n",
       "17451  user_1733657082 2023-02-16 20:22:57.906245  776.82         0   \n",
       "29398  user_7921570811 2020-03-08 14:37:05.027691  472.46         0   \n",
       "58685  user_9757807451 2024-02-19 18:09:45.246353    1.08         0   \n",
       "\n",
       "       user_transaction_amount_totals__amount_sum_1m_continuous  \\\n",
       "2726                                               59.44          \n",
       "64940                                              79.60          \n",
       "17451                                             776.82          \n",
       "29398                                             472.46          \n",
       "58685                                               1.08          \n",
       "\n",
       "       user_transaction_amount_totals__amount_sum_1h_continuous  \\\n",
       "2726                                               59.44          \n",
       "64940                                              79.60          \n",
       "17451                                             776.82          \n",
       "29398                                             472.46          \n",
       "58685                                               1.08          \n",
       "\n",
       "       user_transaction_amount_totals__amount_sum_30d_continuous  \n",
       "2726                                             3215.31          \n",
       "64940                                            3790.19          \n",
       "17451                                            6538.85          \n",
       "29398                                            3991.56          \n",
       "58685                                            6020.50          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tecton import FeatureService\n",
    "\n",
    "fraud_detection_feature_service_streaming = FeatureService(\n",
    "    name=\"fraud_detection_feature_service_streaming\", features=[user_transaction_amount_totals]\n",
    ")\n",
    "\n",
    "# Retrieve our dataset of historical transaction data\n",
    "transactions_df = pd.read_parquet(\"s3://mft-porter-data/tutorials/transactions.pq\", storage_options={\"anon\": True})\n",
    "\n",
    "# Retrieve our dataset of labels containing transaction_id and is_fraud (set to 1 if the transaction is fraudulent or 0 otherwise)\n",
    "training_labels = pd.read_parquet(\"s3://mft-porter-data/tutorials/labels.pq\", storage_options={\"anon\": True})\n",
    "\n",
    "# Join our label dataset to our transaction data to produce a list of training events\n",
    "training_events = training_labels.merge(transactions_df, on=[\"transaction_id\"], how=\"left\")[\n",
    "    [\"user_id\", \"timestamp\", \"amount\", \"is_fraud\"]\n",
    "]\n",
    "\n",
    "# Pass our training events into Tecton to generate point-in-time correct training data\n",
    "training_data = fraud_detection_feature_service_streaming.get_features_for_events(training_events).to_pandas().fillna(0)\n",
    "display(training_data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Apply our Stream Source and Stream Feature View to a Workspace.\n",
    "\n",
    "Once we are happy with our Stream Source and Stream Feature View we can copy the\n",
    "definitions into our Feature Repository and apply our changes to a production\n",
    "workspace using the Tecton CLI.\n",
    "\n",
    "**Note: The workspace must be a live workspace in order to push events to it.**\n",
    "\n",
    "On our Feature View we've added four parameters to enable backfilling, online\n",
    "ingestion, and offline materialization to the Feature Store:\n",
    "\n",
    "- `online=True`\n",
    "- `offline=True`\n",
    "- `feature_start_time=datetime(2020, 1, 1)`\n",
    "- `batch_schedule=timedelta(days=1)`\n",
    "\n",
    "**feature_repo.py**\n",
    "\n",
    "```python\n",
    "from tecton import (\n",
    "    Entity,\n",
    "    BatchSource,\n",
    "    FileConfig,\n",
    "    stream_feature_view,\n",
    "    Aggregation,\n",
    "    StreamSource,\n",
    "    PushConfig,\n",
    "    FeatureService,\n",
    ")\n",
    "from tecton.types import Field, String, Timestamp, Float64\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "transactions_stream = StreamSource(\n",
    "    name=\"transactions_stream\",\n",
    "    stream_config=PushConfig(),\n",
    "    batch_config=FileConfig(\n",
    "        uri=\"s3://mft-porter-data/tutorials/transactions.pq\",\n",
    "        file_format=\"parquet\",\n",
    "        timestamp_field=\"timestamp\",\n",
    "    ),\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    ")\n",
    "\n",
    "user = Entity(name=\"user\", join_keys=[\"user_id\"])\n",
    "\n",
    "\n",
    "@stream_feature_view(\n",
    "    source=transactions_stream,\n",
    "    entities=[user],\n",
    "    mode=\"pandas\",\n",
    "    aggregations=[\n",
    "        Aggregation(function=\"sum\", column=\"amount\", time_window=timedelta(minutes=1)),\n",
    "        Aggregation(function=\"sum\", column=\"amount\", time_window=timedelta(hours=1)),\n",
    "        Aggregation(function=\"sum\", column=\"amount\", time_window=timedelta(days=30)),\n",
    "    ],\n",
    "    schema=[Field(\"user_id\", String), Field(\"timestamp\", Timestamp), Field(\"amount\", Float64)],\n",
    "    online=True,\n",
    "    offline=True,\n",
    "    feature_start_time=datetime(2020, 1, 1),\n",
    "    batch_schedule=timedelta(days=1),\n",
    ")\n",
    "def user_transaction_amount_totals(transactions_stream):\n",
    "    return transactions_stream[[\"user_id\", \"timestamp\", \"amount\"]]\n",
    "\n",
    "\n",
    "fraud_detection_feature_service_streaming = FeatureService(\n",
    "    name=\"fraud_detection_feature_service_streaming\", features=[user_transaction_amount_totals]\n",
    ")\n",
    "```\n",
    "\n",
    "‚úÖ Run the following commands in your terminal to select a workspace and apply\n",
    "your changes:\n",
    "\n",
    "```bash\n",
    "tecton login [your-org-account-name].tecton.ai\n",
    "tecton workspace select [my-live-workspace]\n",
    "tecton apply\n",
    "```\n",
    "\n",
    "## ‚ö°Ô∏è Ingest events and watch values update in real time!\n",
    "\n",
    "Now that our Stream Source has been productionised, we can start sending events\n",
    "to it and watch our aggregations update in real-time!\n",
    "\n",
    "---\n",
    "\n",
    "##### üóíÔ∏è **NOTE**\n",
    "This step requires generating and setting a Tecton API key.\n",
    "\n",
    "To do this, you will need to create a new Service Account and give it access to\n",
    "read features from your workspace.\n",
    "\n",
    "---\n",
    "\n",
    "‚úÖ Head to the following URL to create a new service account (replace \"explore\"\n",
    "with your organization's account name in the URL as necessary). Be sure to save\n",
    "the API key!\n",
    "\n",
    "[https://demo-pangolin.tecton.ai/app/settings/accounts-and-access/service-accounts?create-service-account=true](https://demo-pangolin.tecton.ai/app/settings/accounts-and-access/service-accounts?create-service-account=true)\n",
    "\n",
    "‚úÖ If you are using `demo-pangolin.tecton.ai`, this account will automatically be\n",
    "given the necessary privileges to ingest stream events in the \"prod\" workspace.\n",
    "Otherwise, you should give the service account access to read features from your\n",
    "newly created workspace by following these steps:\n",
    "\n",
    "1. Navigate to the Service Account page by clicking on your new service account\n",
    "   in the list at the URL above\n",
    "2. Click on \"Assign Workspace Access\"\n",
    "3. Select your workspace and give the service account the \"Editor\" role\n",
    "\n",
    "‚úÖ Copy the generated API key into the code snippet below where it says\n",
    "`your-api-key`. Also be sure to replace the workspace name with your newly\n",
    "created workspace name if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully set credentials.\n"
     ]
    }
   ],
   "source": [
    "# Use your API key generated in the step above\n",
    "TECTON_API_KEY = \"your-api-key\"  # replace with your API key\n",
    "WORKSPACE_NAME = \"prod\"  # replace with your new workspace name if needed\n",
    "\n",
    "tecton.set_credentials(tecton_api_key=TECTON_API_KEY)\n",
    "\n",
    "ws = tecton.get_workspace(WORKSPACE_NAME)\n",
    "transactions_stream_source = ws.get_data_source(\"transactions_stream\")\n",
    "fraud_detection_feature_service_streaming = ws.get_feature_service(\"fraud_detection_feature_service_streaming\")\n",
    "\n",
    "# Generate a random user_id for the next step\n",
    "user_id = \"\".join(random.choices(string.ascii_letters + string.digits, k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚≠êÔ∏è Try repeatedly running these steps in quick succession and watch feature\n",
    "values update in real-time!‚≠êÔ∏è\n",
    "\n",
    "---\n",
    "\n",
    "##### üóíÔ∏è **NOTE**\n",
    "\n",
    "Service account permissions may take a few minutes to update. Also, your first ingestion call may take longer than the rest.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ingestMetrics': {'featureViewIngestMetrics': [{'featureViewId': '73ed15b75c519022d5508f86de28c9b9',\n",
      "                                                 'featureViewName': 'user_transaction_amount_totals',\n",
      "                                                 'onlineRecordIngestCount': '1'}]},\n",
      " 'workspaceName': 'prod'}\n"
     ]
    }
   ],
   "source": [
    "# Ingest events\n",
    "try:\n",
    "    response = transactions_stream_source.ingest({\"user_id\": user_id, \"timestamp\": datetime.utcnow(), \"amount\": 101})\n",
    "    pprint(response)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        \"Error: Your API key permissions may not yet have updated, or perhaps you didn't set the right API key and workspace name above.\\n\",\n",
    "        e,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_transaction_amount_totals.amount_sum_1h_continuous': 101.0,\n",
      " 'user_transaction_amount_totals.amount_sum_1m_continuous': 101.0,\n",
      " 'user_transaction_amount_totals.amount_sum_30d_continuous': 101.0}\n"
     ]
    }
   ],
   "source": [
    "# Read updated feature values\n",
    "try:\n",
    "    features = fraud_detection_feature_service_streaming.get_online_features(join_keys={\"user_id\": user_id})\n",
    "    pprint(features.to_dict())\n",
    "\n",
    "except Exception as e:\n",
    "    print(\n",
    "        \"Error: Your API key permissions may not yet have updated, or perhaps you didn't set the right API key and workspace name above.\\n\",\n",
    "        e,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### üí° **TIP**\n",
    "\n",
    "The `.ingest()` method makes it easy to push events from a notebook. In production we recommend pushing events directly to the HTTP endpoint for the best performance.\n",
    "\n",
    "The same goes for reading online data from a Feature Service via `.get_online_features()`. For best performance we recommend reading directly from the HTTP API or using our [Python Client Library](https://docs.tecton.ai/docs/reading-feature-data/reading-feature-data-for-inference/reading-online-features-for-inference-using-the-python-client).\n",
    "\n",
    "---\n",
    "\n",
    "## ‚≠êÔ∏è Conclusion\n",
    "\n",
    "There you have it! Using nothing but Python and a local dev environment we were\n",
    "able to get real-time features running online and ready to consume by a\n",
    "production model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
